# IllustrationGAN
A simple, clean TensorFlow implementation of Generative Adversarial Networks with a focus on modeling illustrations.

## Generated Images
These images were generated by the model after being trained on a custom dataset of about 20,000 anime faces that were automatically cropped from illustrations using a face detector.
![Generated Images](images/montage.png?raw=True)

## Checking for Overfitting
It is theoretically possible for the generator network to memorize training set images rather than actual generalizing and learning to produce novel images of its own. To check for this, I randomly generate images and display the "closest" images in the training set according to mean squared error. The top row is randomly generated images, the columns are the closest 5 images in the training set.

![Overfitting Check](images/overfitting_check.png?raw=True)

It is clear that the generator does not merely learn to copy training set images, but rather generalizes and is able to produce its own unique images.

## How it works
Generative Adversarial Networks consist of two neural networks: a discriminator and a generator. The discriminator receives both real images from the training set and generated images produced by the generator. The discriminator outputs the probability that an image is real, so it is trained to output high values for the real images and low values for the generated ones. The generator is trained to produce images that the discriminator thinks are real. Both the discriminator and generator are trainined simultaneously so that they compete against each other. As a result of this, the generator learns to produce more and more realistic images as it trains.

## Training the model
Dependencies: TensorFlow, PrettyTensor, numpy, matplotlib

The custom dataset I used is too large to add to a Github repository; I am currently finding a suitable way to distribute it. Instructions for training the model will be in this readme after I make the dataset available.
